{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4378830d94131c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:18.712848Z",
     "start_time": "2025-02-12T09:39:18.655717Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01c622438f1378",
   "metadata": {},
   "source": [
    "# Multitask Classification with SELFIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a38c2323bcf43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:18.907115Z",
     "start_time": "2025-02-12T09:39:18.839087Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from Code.Utils.util_methods import NNUtils\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "import logging\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "import selfies as sf\n",
    "from tqdm import tqdm\n",
    "import deepchem as dc\n",
    "import json\n",
    "\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "base = NNUtils.find_project_root(os.getcwd())\n",
    "print(f\"Project root found: {base}\")\n",
    "\n",
    "load_dotenv(f'{base}/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:19.137138Z",
     "start_time": "2025-02-12T09:39:19.033854Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/{os.getenv(\"X_TRAIN\")}')#.loc[:10000]\n",
    "X_test = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/{os.getenv(\"X_TEST\")}')#.loc[:10000]\n",
    "y_train = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/{os.getenv(\"Y_TRAIN\")}')#.loc[:10000]\n",
    "y_test = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/{os.getenv(\"Y_TEST\")}')#.loc[:10000]\n",
    "#X = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/X.pkl')\n",
    "#y = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/y.pkl')\n",
    "selfies_X_test = pd.read_pickle(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/selfies_X_test.pkl')#.loc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb655367914e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:19.340767Z",
     "start_time": "2025-02-12T09:39:19.252585Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d292856d62cca39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:19.780908Z",
     "start_time": "2025-02-12T09:39:19.688689Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d87aa",
   "metadata": {},
   "source": [
    "Create a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35f6e7-e003-4770-b2ee-9feef9287967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:21.095588Z",
     "start_time": "2025-02-12T09:39:21.034680Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'The size of the training set is: {X_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c66fc3f29ca209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:23.494353Z",
     "start_time": "2025-02-12T09:39:23.404998Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform into deepchem datasets\n",
    "train_dataset = dc.data.NumpyDataset(X_train, y_train)\n",
    "test_dataset = dc.data.NumpyDataset(X_test, y_test)\n",
    "#ds = dc.data.DiskDataset.from_numpy(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c802ee16ba7afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:23.798143Z",
     "start_time": "2025-02-12T09:39:23.732781Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'train: {train_dataset}')\n",
    "print(f'test: {test_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ee422d12cdc28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:30.302603Z",
     "start_time": "2025-02-12T09:39:30.241011Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{base}/Code/Full_systems/Selfies_Mol/Featurization/selfies_group_dict.json', 'r') as json_file:\n",
    "    selfies_group_dict = json.load(json_file)\n",
    "selfies_group_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88634ff6d1a7ca16",
   "metadata": {},
   "source": [
    "Train a multitask model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a32076-90dc-44c6-a3fb-647cd142e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochCallback:\n",
    "    def __init__(self, steps_per_epoch):\n",
    "        \"\"\"\n",
    "        Initialize the callback with the number of steps per epoch.\n",
    "        \"\"\"\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.current_step = 0  # Tracks the global step count\n",
    "        self.current_epoch = 0  # Tracks the epoch count\n",
    "\n",
    "    def __call__(self, model, step):\n",
    "        \"\"\"\n",
    "        This method is called at the end of each training step.\n",
    "        \"\"\"\n",
    "        self.current_step += 1\n",
    "        # Check if the current step marks the end of an epoch\n",
    "        if self.current_step % self.steps_per_epoch == 0:\n",
    "            self.current_epoch += 1\n",
    "            print(f\"Epoch {self.current_epoch} completed at step {self.current_step}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d472dad-28d3-44b5-ab64-23ae9b7ddde0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:30.625151Z",
     "start_time": "2025-02-12T09:39:30.565594Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressBarCallback:\n",
    "    def __init__(self, steps_per_epoch, total_epochs):\n",
    "        \"\"\"\n",
    "        Initialize the progress bar callback.\n",
    "        \"\"\"\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.current_step = 0\n",
    "        self.current_epoch = 0\n",
    "        self.pbar = None  # Placeholder for the progress bar\n",
    "\n",
    "    def __call__(self, model, step):\n",
    "        \"\"\"\n",
    "        Update the progress bar at each step.\n",
    "        \"\"\"\n",
    "        if self.pbar is None:  # Initialize the progress bar at the start\n",
    "            self.pbar = tqdm(total=self.steps_per_epoch * self.total_epochs, desc=\"Training Progress\", unit=\"step\")\n",
    "\n",
    "        # Update the progress bar\n",
    "        self.pbar.update(1)\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Check if an epoch is completed\n",
    "        if self.current_step % self.steps_per_epoch == 0:\n",
    "            self.current_epoch += 1\n",
    "            print(f\"Epoch {self.current_epoch}/{self.total_epochs} completed.\")\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the progress bar when training is done.\n",
    "        \"\"\"\n",
    "        if self.pbar is not None:\n",
    "            self.pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a1200-610d-48ef-a41d-57216d80e756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:39:30.745525Z",
     "start_time": "2025-02-12T09:39:30.686043Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0708730b4e5bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:17.830455Z",
     "start_time": "2025-02-12T09:39:30.883258Z"
    }
   },
   "outputs": [],
   "source": [
    "dc.utils.logger.setLevel(logging.INFO)\n",
    "\n",
    "batch_size = 50 #50 by defalut\n",
    "epochs = 50\n",
    "\n",
    "model = dc.models.MultitaskClassifier(\n",
    "    n_tasks=y_train.shape[1],\n",
    "    n_features=int(os.getenv('MAX_MASS')),\n",
    "    layer_sizes=[1000, 1000, 1000], #3000, 1000, #3000, 2000\n",
    "    dropouts=0.1\n",
    "    #activation_fns=['relu', 'relu', 'sigmoid'],\n",
    "    #learning_rate=0.001,\n",
    "    #batch_size = batch_size\n",
    ")\n",
    "steps_per_epoch = X_train.shape[0] // batch_size\n",
    "epoch_callback = EpochCallback(steps_per_epoch)\n",
    "progress_bar_callback = ProgressBarCallback(steps_per_epoch, epochs)\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=epochs, callbacks=[progress_bar_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4f90e-7260-4bd5-b78a-a2ee62af8957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:17.994145Z",
     "start_time": "2025-02-12T09:40:17.933374Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize your DeepChem model\n",
    "# model = dc.models.MultitaskClassifier(\n",
    "#     n_tasks=y_train.shape[1],\n",
    "#     n_features=int(os.getenv('MAX_MASS')),\n",
    "#     batch_size=128  # Example batch size\n",
    "# )\n",
    "\n",
    "# # Wrap the model with DCLightningModule\n",
    "# lit_model = DCLightningModule(model)\n",
    "\n",
    "# # Prepare your dataset\n",
    "# train_dataset_module = DCLightningDatasetModule(train_dataset, batch_size=128, collate_fn=collate_dataset_wrapper)\n",
    "\n",
    "# # Initialize the PyTorch Lightning trainer with GPU settings\n",
    "# trainer = pl.Trainer(max_epochs=10, devices=1, accelerator='gpu', strategy='ddp_notebook')  # Adjust devices as needed\n",
    "\n",
    "# # Train the model\n",
    "# trainer.fit(lit_model, train_dataset_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e3899-a999-4219-b093-9af4ef9bea4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:18.150831Z",
     "start_time": "2025-02-12T09:40:18.090475Z"
    }
   },
   "outputs": [],
   "source": [
    "progress_bar_callback.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e97913518a5b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:18.486638Z",
     "start_time": "2025-02-12T09:40:18.236854Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46997cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:18.649514Z",
     "start_time": "2025-02-12T09:40:18.585309Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f593572df44c274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:45.309506Z",
     "start_time": "2025-02-12T09:40:18.789770Z"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "\n",
    "# NOT CORRECT YET!!\n",
    "# THE [nop] SHOULD NOT BE INCLUDED IN THE EVALUATION !!!\n",
    "\n",
    "tp=[] # true positive\n",
    "fn=[] # false negative\n",
    "fp=[] # false positive\n",
    "pr=[] # total number of predicted bits\n",
    "tp_p=[] # true pos %\n",
    "fp_p=[] # false pos %\n",
    "\n",
    "cutoff = 0.5    # predicted >= 0.5 will turn bit=1\n",
    "\n",
    "for q in tqdm(range(len(test_dataset)), desc='Loop over all test molecules'):   # loop over all test molecules\n",
    "\n",
    "  # get predicted fingerprint of molecule q\n",
    "  pred = []\n",
    "  for i in predictions[q]:\n",
    "    if i[1] >= cutoff:\n",
    "      pred.append(1)\n",
    "    else:\n",
    "      pred.append(0)\n",
    "\n",
    "  # get real fingerprint of molecule q\n",
    "  real = test_dataset.y[q]\n",
    "\n",
    "  bit = 0\n",
    "  a=0\n",
    "  b=0\n",
    "  c=0\n",
    "  d=0\n",
    "  e=0\n",
    "\n",
    "  for i in range(int(os.getenv(\"ENCODING_BITS\"))*int(os.getenv(\"MAX_SELFIES_LENGTH\"))):\n",
    "    if real[i]==1 and pred[i]==1:     # true pos (correct prediction)\n",
    "      a=a+1\n",
    "    if real[i]==1 and pred[i]==0:     # false neg (missed)\n",
    "      b=b+1\n",
    "    if real[i]==0 and pred[i]==1:     # false pos (not correct)\n",
    "      c=c+1\n",
    "    if real[i]==1: # count number of 'on-bits'\n",
    "      d=d+1\n",
    "    if pred[i]==1: # count number of predicted 'on-bits'\n",
    "      e=e+1\n",
    "  \n",
    "  epsilon = 10e-7\n",
    "  \n",
    "  tp.append(a)  # true pos\n",
    "  fn.append(b)  # false neg\n",
    "  fp.append(c)  # false pos\n",
    "  pr.append(e)  # number of predicted on-bits\n",
    "  fp_p.append(int(c/(e+epsilon)*100)) # false pos / predicted on-bits * 100%\n",
    "  tp_p.append(int(a/(d+epsilon)*100)) # true pos / real number on-bits * 100%\n",
    "\n",
    "# % True positive average, stdev and cv% for all test molecules\n",
    "avg = int (mean(tp_p))\n",
    "sd = int (stdev(tp_p))\n",
    "cv = int (sd/avg*100)\n",
    "print (f'BITWISE EVALUATION OF TEST_DATASET CONTAINING: {len(test_dataset)} MOLECULES')\n",
    "print (f'--------------------------------------------------------------------')\n",
    "print (f'TRUE POS:    AVG={avg}%    STDEV={sd}    CV%={cv}')\n",
    "\n",
    "# % False positive average, stdev and cv% for all test molecules\n",
    "avg = int (mean(fp_p))\n",
    "sd = int (stdev(fp_p))\n",
    "cv = int (sd/avg*100)\n",
    "print (f'FALSE POS:   AVG={avg}%    STDEV={sd}    CV%={cv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694a9586b36dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionairy (itos) to transfer the hot-encoding array into a array of SELFIES and SMILES\n",
    "itos={}\n",
    "c=0\n",
    "for i in selfies_group_dict:\n",
    "  itos[selfies_group_dict[i]]=i\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ed340b6892b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:54.838293Z",
     "start_time": "2025-02-12T09:40:45.598947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation whole test set\n",
    "# check if predicted smiles == real smiles\n",
    "\n",
    "cutoff = 0.5\n",
    "hit = 0\n",
    "score=[]\n",
    "to_print = []\n",
    "\n",
    "columns = ['SMILES_ID', 'Original_SMILES', 'Predicted_SMILES', 'Original_SELFIES', 'Predicted_SELFIES', 'Fingerprint_SIMILARITY', 'SELFIES_SIMILARITY']\n",
    "res_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for test_compound_id in tqdm(range(len(test_dataset)), desc='Evaluate all test molecules'):   # loop over all test molecules\n",
    "  # create hot-encoding array of molecule id\n",
    "  pred = []\n",
    "  for i in predictions[test_compound_id]:\n",
    "    if i[1] >= cutoff:\n",
    "      pred.append(1)\n",
    "    else:\n",
    "      pred.append(0)\n",
    "\n",
    "  sfc =''\n",
    "  a = len(pred)   # 5096\n",
    "  b = len(itos)   # 56\n",
    "  c = int (a/b)   # 91\n",
    "\n",
    "  for i in range(c):\n",
    "    for q in range(b):\n",
    "      if pred[i*b+q]==1 and itos[q]!='[nop]':\n",
    "        # print (itos[q])\n",
    "        sfc = sfc + (itos[q])\n",
    "  sf_m = sf.decoder(sfc)\n",
    "\n",
    "  # real molecule\n",
    "  #compound_id = test_dataset.ids[test_compound_id]\n",
    "  real_selfies = selfies_X_test.loc[test_compound_id]\n",
    "  smile_id = sf.decoder(real_selfies)\n",
    "\n",
    "    # Convert SMILES to RDKit molecule object\n",
    "  mol_a = Chem.MolFromSmiles(sf_m)\n",
    "  mol_b = Chem.MolFromSmiles(smile_id)\n",
    "  \n",
    "  # Only proceed if both molecules are valid\n",
    "  if mol_a is not None and mol_b is not None:\n",
    "    a = Chem.RDKFingerprint(mol_a)\n",
    "    b = Chem.RDKFingerprint(mol_b)\n",
    "    score.append(DataStructs.FingerprintSimilarity(a, b, metric=DataStructs.DiceSimilarity))\n",
    "    #to_print.append(f'{test_compound_id} ------- {sf_m} -------- {smile_id} {DataStructs.FingerprintSimilarity(a,b, metric=DataStructs.DiceSimilarity)}')\n",
    "    fingerprint_similarity = DataStructs.FingerprintSimilarity(a,b, metric=DataStructs.DiceSimilarity)\n",
    "    selfies_similarity = NNUtils.selfies_similarity(real_selfies, sfc)\n",
    "    res_df.loc[test_compound_id] = [test_compound_id, smile_id, sf_m, real_selfies, sfc, fingerprint_similarity, selfies_similarity]\n",
    "    \n",
    "    if sf_m == smile_id:\n",
    "      hit = hit + 1\n",
    "      \n",
    "  else:\n",
    "    #print(\"Invalid molecule found, skipping.\")\n",
    "    pass\n",
    "\n",
    "res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03068ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['SELFIES_SIMILARITY'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348e0edfc046074",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.array(score)\n",
    "sum_score_1 = sum(score>=1)\n",
    "sum_score_09 = sum(score>=0.9)\n",
    "sum_score_06 = sum(score>=0.6)\n",
    "\n",
    "print (f'Correct smiles predictions: {hit} (={int(hit/len(test_dataset.X)*100)}%). Test set contains in total {len(test_dataset.X)} compounds.')\n",
    "print (f'Tanimoto similarity >= 1.0: {sum_score_1} (={int(sum_score_1/len(test_dataset.X)*100)}%). Test set contains in total {len(test_dataset.X)} compounds.')\n",
    "print (f'Tanimoto similarity >= 0.9: {sum_score_09} (={int(sum_score_09/len(test_dataset.X)*100)}%). Test set contains in total {len(test_dataset.X)} compounds.')\n",
    "print (f'Tanimoto similarity >= 0.6: {sum_score_06} (={int(sum_score_06/len(test_dataset.X)*100)}%). Test set contains in total {len(test_dataset.X)} compounds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec00a5-9449-46d1-b5ba-fbbcd0b42098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:40:55.279117Z",
     "start_time": "2025-02-12T09:40:55.273621Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
